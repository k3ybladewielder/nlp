{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzTQZ_itJ8hK"
      },
      "source": [
        "# Homework and bakeoff: Multi-domain sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BB7OsFw3rhdb"
      },
      "outputs": [],
      "source": [
        "__author__ = \"Alysson Guimar√£es\"\n",
        "__version__ = \"CS224u, Stanford, Spring 2023\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpKZSqtNrhde"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cgpotts/cs224u/blob/main/hw_sentiment.ipynb)\n",
        "[![Open in SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/cgpotts/cs224u/blob/main/hw_sentiment.ipynb)\n",
        "\n",
        "If Colab is opened with this badge, please **save a copy to drive** (from the File menu) before running the notebook."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E27QqTcguZJr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BiIoTMjrhdf"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUNrgZrPrhdg"
      },
      "source": [
        "This homework and associated bakeoff are devoted to supervised sentiment analysis in a ternary label setting (positive, negative, neutral). Your ultimate goal is to develop systems that can make accurate predictions in multiple domains."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAFlPLi8rhdg"
      },
      "source": [
        "The homework questions ask you to implement some baseline systems using DynaSent Round 1, DynaSent Round 2, and the Stanford Sentiment Treebank. The bakeoff challenge is to define a system that does well on the DynaSent test sets, the SST-3 test set, and a set of mystery examples that don't correspond to the DynaSent or SST-3 domains."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj0QVml-rhdh"
      },
      "source": [
        "__Important methodological note:__ The DynaSent and SST-3 test sets are already publicly distributed, so we are counting on people not to cheat by developing their models on these test sets. You must do all your development without using these test sets at all, and then evaluate exactly once on the test set and turn in the results, with no further system tuning or additional runs. _Much of the scientific integrity of our field depends on people adhering to this honor code._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZtyJXCQrhdi"
      },
      "source": [
        "This notebook briefly introduces our three development datasets, states the homework questions, and then provides guidance on the original system and associated bakeoff entry."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsLcqWtBJ8hM"
      },
      "source": [
        "## Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2nFUcNIhJ8hM"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    # Sort of randomly chosen import to see whether the requirements\n",
        "    # are met:\n",
        "    import datasets\n",
        "except ModuleNotFoundError:\n",
        "    !git clone https://github.com/cgpotts/cs224u/\n",
        "    !pip install -r cs224u/requirements.txt\n",
        "    import sys\n",
        "    sys.path.append(\"cs224u\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pyAzJmyYSNMP"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict, Counter\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdJba1bGJ8hN"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGAwU8KmJ8hN"
      },
      "source": [
        "### DynaSent round 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkApcjnOrhdl"
      },
      "source": [
        "The DynaSent dataset of [Potts, Wu, et al. 2021](https://aclanthology.org/2021.acl-long.186/) is a ternary sentiment benchmark consisting of two rounds (so far). The dataset is available on [Hugging Face](https://huggingface.co/datasets/dynabench/dynasent)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSDOmNqorhdl"
      },
      "source": [
        "For Round 1, the authors collected sentences from the [Yelp Academic Dataset](https://www.yelp.com/dataset) that fooled a top-performing sentiment model but were intuitive for humans. The model was used only to heuristically find the examples. Crowdworkers multiply-labeled all of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLuZtuourhdl"
      },
      "source": [
        "The round contains a lot of metadata that could be useful for developing sentiment models. We will focus on just the sentences and labels, but you are free to make use of this additional metadata in developing uour system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "7057d7bf33d74ed4b17beea4a59ef0e3",
            "7e55b5182ddb40a99d76fdbc8f7d706e",
            "0df4d264a8fd4d1c9c2a7d758c6f6cd4",
            "b86c0a101c1048ff9d20b551f459643d",
            "a7f79187a8d74ed280920c56aa4a2c26",
            "404e8edecc3e4ae9b48e9e647d25bd29",
            "96dd7bf00d5b49578885ff2f8a8ff45f",
            "be23ca8c5b54424fa0735fcdd687619e",
            "c5429e1f2bc14a209200a9f66337b06e",
            "b42ed1ae59364c22a0d70adff97cdc10",
            "ba3c5f0f91c445d089b8023fc2b4cd1f"
          ]
        },
        "id": "j9UcNgx_SZDG",
        "outputId": "3892d90b-ebfd-48b7-d194-b59fc3cd560f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset dynasent (/root/.cache/huggingface/datasets/dynabench___dynasent/dynabench.dynasent.r1.all/1.1.0/ab89971d9ae1aacc59ed44d6855bf0e89167417257e2c2666f38e532148f2967)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7057d7bf33d74ed4b17beea4a59ef0e3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "dynasent_r1 = load_dataset(\"dynabench/dynasent\", 'dynabench.dynasent.r1.all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7iN05xzSkKo",
        "outputId": "25b3dde1-3d9d-435c-fe65-1f11481cc0a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'hit_ids', 'sentence', 'indices_into_review_text', 'model_0_label', 'model_0_probs', 'text_id', 'review_id', 'review_rating', 'label_distribution', 'gold_label', 'metadata'],\n",
              "        num_rows: 80488\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'hit_ids', 'sentence', 'indices_into_review_text', 'model_0_label', 'model_0_probs', 'text_id', 'review_id', 'review_rating', 'label_distribution', 'gold_label', 'metadata'],\n",
              "        num_rows: 3600\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'hit_ids', 'sentence', 'indices_into_review_text', 'model_0_label', 'model_0_probs', 'text_id', 'review_id', 'review_rating', 'label_distribution', 'gold_label', 'metadata'],\n",
              "        num_rows: 3600\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dynasent_r1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_iWixX6J8hO"
      },
      "source": [
        "Splits:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RVjcdb_4SrS2"
      },
      "outputs": [],
      "source": [
        "def print_label_dist(dataset, labelname='gold_label', splitnames=('train', 'validation')):\n",
        "    for splitname in splitnames:\n",
        "        print(splitname)\n",
        "        dist = sorted(Counter(dataset[splitname][labelname]).items())\n",
        "        for k, v in dist:\n",
        "            print(f\"\\t{k:>14s}: {v}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3RQdIBRJ8hP",
        "outputId": "e3d1450b-17dc-4615-da41-63c16a1f4442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "\t      negative: 14021\n",
            "\t       neutral: 45076\n",
            "\t      positive: 21391\n",
            "validation\n",
            "\t      negative: 1200\n",
            "\t       neutral: 1200\n",
            "\t      positive: 1200\n"
          ]
        }
      ],
      "source": [
        "print_label_dist(dynasent_r1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4WFt0C6J8hP"
      },
      "source": [
        "### DynaSent round 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEsOddZorhdn"
      },
      "source": [
        "DynaSent Round 2 was created using different methods than Round 1. For Round 2, crowdworkers edited sentences from the Yelp Academic Dataset seeking to achieve a particular sentiment goal (e.g., expressing a positive sentiment) while fooling a top-performing model. This work was done on the [Dynabench](https://dynabench.org) platform. The hope is that this directly adversarial goal will lead to examples that are very hard for present-day models but intuitive for humans. All the examples were multiply-labeled by separate annotators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "f66b59a0ccf24a3299bba1cc727b7e2b",
            "55e8efbca3d54af6a92361a190cb89fe",
            "4481997146954fb2b6ee9b8963617ef6",
            "c1d43a8ddff449e0a315389b0674f218",
            "15bb2f3e44a04b3f9a896faaadf5f3b2",
            "d7d51c21bc0642109783e056b4753987",
            "f4819479b0a64d79a0bf014967c21c03",
            "b7261a38a3e24d3db23a1c76903b58cb",
            "6b9634a5d8ce47ef8921ca57c42313e6",
            "b9f0c4da0a6b42b09ed2718b3256c269",
            "123e313617f84d53acbbafb50ae6d59f"
          ]
        },
        "id": "iz3F_lviJ8hP",
        "outputId": "a13af56a-b838-4620-f7ab-f5d3ce15d780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset dynasent (/root/.cache/huggingface/datasets/dynabench___dynasent/dynabench.dynasent.r2.all/1.1.0/ab89971d9ae1aacc59ed44d6855bf0e89167417257e2c2666f38e532148f2967)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f66b59a0ccf24a3299bba1cc727b7e2b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "dynasent_r2 = load_dataset(\"dynabench/dynasent\", 'dynabench.dynasent.r2.all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up68q68dJ8hP",
        "outputId": "7bafbf7a-8fbf-44f0-f0b3-938011937cbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "\t      negative: 4579\n",
            "\t       neutral: 2448\n",
            "\t      positive: 6038\n",
            "validation\n",
            "\t      negative: 240\n",
            "\t       neutral: 240\n",
            "\t      positive: 240\n"
          ]
        }
      ],
      "source": [
        "print_label_dist(dynasent_r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeONNIJQJ8hP"
      },
      "source": [
        "### Stanford Sentiment Treebank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJBL1fDUrhdo"
      },
      "source": [
        "The [Stanford Sentiment Treebank (SST)](http://nlp.stanford.edu/sentiment/) of [Socher et al. 2013](https://aclanthology.org/D13-1170/) is a widely-used resource for evaluating supervised models. It consists of sentences from Rotten Tomatoes Movie Reviews (see [Pang and Lee's project page](https://www.cs.cornell.edu/home/llee/papers/pang-lee-stars.home.html)). We will use the ternary version of the task (SST-3)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffU4IJ51rhdo"
      },
      "source": [
        "SST examples are special in that they are labeled at the phrase-level as well as the sentence level, which provides very extensive and detailed supervision for sentiment. We will use only the sentence-level labels for the homework, but you are free to use the phrase-level labels as well in designing your original system. (To do this, you will need to get the dataset from the above project page, since the Hugging Face SST-3 we are using does not include these labels.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "590a9510737945c6beda1ce1d13f7baa",
            "112c6de994e74ed0a4eeafe66fe65fdf",
            "bd5cb3e93b4b45908dd9d526d8b77ced",
            "3553377c78e540759134b292e5ec5b14",
            "5abef5baebbb4e8e8a1b4e427e3e6873",
            "7ef05d3796044e49adaab3299749cfa6",
            "01d91b198f654c988846e213abdcc360",
            "06d4e47fcd6a46a68e5ee75d341fb898",
            "1cc80309f70b48078f9b1bebc977076b",
            "c073cae37bb545f38fffcbb3e810fa78",
            "e487f831c66e4306aa70891435b8c132"
          ]
        },
        "id": "rJROF2MaJ8hP",
        "outputId": "09d8fd5e-2fb2-4943-d956-d9bccc530511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-4c07b9d5881ae209/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "590a9510737945c6beda1ce1d13f7baa"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "sst = load_dataset(\"SetFit/sst5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw0I60nOJ8hQ",
        "outputId": "2ccc52ad-3ab5-4406-9b48-e95ba9fdba19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label', 'label_text'],\n",
              "        num_rows: 8544\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label', 'label_text'],\n",
              "        num_rows: 2210\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label', 'label_text'],\n",
              "        num_rows: 1101\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "sst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYas8mLkrhdp"
      },
      "source": [
        "Out of the box, this is a five-way task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxmbH6qkJ8hQ",
        "outputId": "6eb43b9b-ca86-4905-ccf9-94c601812d62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "\t      negative: 2218\n",
            "\t       neutral: 1624\n",
            "\t      positive: 2322\n",
            "\t very negative: 1092\n",
            "\t very positive: 1288\n",
            "validation\n",
            "\t      negative: 289\n",
            "\t       neutral: 229\n",
            "\t      positive: 279\n",
            "\t very negative: 139\n",
            "\t very positive: 165\n"
          ]
        }
      ],
      "source": [
        "print_label_dist(sst, labelname='label_text')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRAu59X8rhdp"
      },
      "source": [
        "The above labels are not aligned with our ternary task, and the dataset distribution uses slightly different keys from those of DynaSent. The following code converts the dataset to SST-3 and also aligns the dataset keys:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WDgWI8IzJ8hQ"
      },
      "outputs": [],
      "source": [
        "def convert_sst_label(s):\n",
        "    return s.split(\" \")[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UDT2FS0RJ8hQ"
      },
      "outputs": [],
      "source": [
        "for splitname in ('train', 'validation', 'test'):\n",
        "    dist = [convert_sst_label(s) for s in sst[splitname]['label_text']]\n",
        "    sst[splitname] = sst[splitname].add_column('gold_label', dist)\n",
        "    sst[splitname] = sst[splitname].add_column('sentence', sst[splitname]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-dl9asPJ8hQ",
        "outputId": "c8fa2fb4-2272-4d0d-88e9-45982fae4e7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "\t      negative: 3310\n",
            "\t       neutral: 1624\n",
            "\t      positive: 3610\n",
            "validation\n",
            "\t      negative: 428\n",
            "\t       neutral: 229\n",
            "\t      positive: 444\n"
          ]
        }
      ],
      "source": [
        "print_label_dist(sst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLpGbSxjrhdq"
      },
      "source": [
        "## Question 1: Linear classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHPgdpfuJ8hQ"
      },
      "source": [
        "Our first set of experiments will use simple linear classifiers with sparse representations derived from counting unigrams. These experiments will introduce some useful techniques and provide a baseline for original systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3QK5Wcorhdq"
      },
      "source": [
        "### Background: Feature functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKKfA38Hrhdz"
      },
      "source": [
        "The following is a flexible format for writing feature functions in the context of scikit-learn modeling. The function maps a string to a count dictionary, using the simple procedure of splitting on whitespace and counting the resulting elements:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "85aaSLXerhdz"
      },
      "outputs": [],
      "source": [
        "def unigrams_phi(s):\n",
        "    \"\"\"The basis for a unigrams feature function.\n",
        "\n",
        "    Downcases all tokens.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    s : str\n",
        "        The example to represent\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Counter\n",
        "        A map from tokens (str) to their counts in `text`\n",
        "\n",
        "    \"\"\"\n",
        "    return Counter(s.lower().split())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng066k9Yrhd0"
      },
      "source": [
        "Quick example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhI69H5erhd0",
        "outputId": "d2daf7ba-a41d-4334-a532-408f49720107"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({\"here's\": 1,\n",
              "         'an': 2,\n",
              "         'example': 1,\n",
              "         'with': 1,\n",
              "         'emoticon': 1,\n",
              "         ':)!': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "unigrams_phi(\"Here's an example with an emoticon :)!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trdPrLyMrhd0"
      },
      "source": [
        "### Background: Feature space vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQwtW45Brhd0"
      },
      "source": [
        "Functions like `unigrams_phi`  are just the __basis__ for feature representations. In truth, our models typically don't represent examples as dictionaries, but rather as vectors embedded in a matrix. In general, to manage the translation from dictionaries to vectors, we use [sklearn.feature_extraction.DictVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) instances. Here's a brief overview of how these work:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R66fmmEPrhd0"
      },
      "source": [
        "To start, suppose that we had just two examples to represent, and our feature function mapped them to the following list of dictionaries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gg_IggoMrhd1"
      },
      "outputs": [],
      "source": [
        "train_feats = [\n",
        "    {'a': 1, 'b': 1},\n",
        "    {'b': 1, 'c': 2}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64Lmzwj2rhd1"
      },
      "source": [
        "Now we create a `DictVectorizer`. So that we can more easily inspect the resulting matrix, I've set `sparse=False`, so that the return value is a dense matrix. For real problems, you'll probably want to use `sparse=True`, as it will be vastly more efficient for the very sparse feature matrices that you are likely to be creating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aiOfsQr9rhd1"
      },
      "outputs": [],
      "source": [
        "vec = DictVectorizer(sparse=False)  # Use `sparse=True` for real problems!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y2iWdkOrhd1"
      },
      "source": [
        "The `fit_transform` method maps our list of dictionaries to a matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "av5S4XHErhd2"
      },
      "outputs": [],
      "source": [
        "X_train = vec.fit_transform(train_feats)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAmLPQblwEA0",
        "outputId": "018b758a-bc9f-4e30-ac01-788a637f4d5a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 0.],\n",
              "       [0., 1., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejUNUZAIrhd2"
      },
      "source": [
        "Here I'll create a `pd.Datafame` just to help us inspect `X_train`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "MDkcdhygrhd2",
        "outputId": "a8cee59e-5cdd-4bc5-fe3a-1bd4139f89d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     a    b    c\n",
              "0  1.0  1.0  0.0\n",
              "1  0.0  1.0  2.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6788a85-9de2-4b01-8522-f900d94e3007\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6788a85-9de2-4b01-8522-f900d94e3007')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a6788a85-9de2-4b01-8522-f900d94e3007 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a6788a85-9de2-4b01-8522-f900d94e3007');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-09abd8e7-499a-43a9-b24f-61ee72d2b597\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-09abd8e7-499a-43a9-b24f-61ee72d2b597')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-09abd8e7-499a-43a9-b24f-61ee72d2b597 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "pd.DataFrame(X_train, columns=vec.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvMsjODUrhd2"
      },
      "source": [
        "Now we can see that, intuitively, the feature called \"a\" is embedded in the first column, \"b\" in the second column, and \"c\" in the third."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ktIk0yFrhd3"
      },
      "source": [
        "Now suppose we have some new test examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nqRkLHJSrhd3"
      },
      "outputs": [],
      "source": [
        "test_feats = [\n",
        "    {'a': 2, 'c': 1},\n",
        "    {'a': 4, 'b': 2, 'd': 1}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyW87KSRrhd3"
      },
      "source": [
        "If we have trained a model on `X_train`, then it will not have any way to deal with this new feature \"d\". This shows that we need to embed `test_feats` in the same space as `X_train`. To do this, one just calls `transform` on the existing vectorizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "s1-J4CACrhd3"
      },
      "outputs": [],
      "source": [
        "X_test = vec.transform(test_feats)  # Not `fit_transform`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "XCm1mzpOrhd4",
        "outputId": "4d83c07d-1e36-461f-df8d-c848e16a6d73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     a    b    c\n",
              "0  2.0  0.0  1.0\n",
              "1  4.0  2.0  0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39cf517e-c4c8-4295-b94d-26ee8f8808d1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39cf517e-c4c8-4295-b94d-26ee8f8808d1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-39cf517e-c4c8-4295-b94d-26ee8f8808d1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-39cf517e-c4c8-4295-b94d-26ee8f8808d1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-565c7507-d559-4306-b45d-671bca7f74bd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-565c7507-d559-4306-b45d-671bca7f74bd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-565c7507-d559-4306-b45d-671bca7f74bd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "pd.DataFrame(X_test, columns=vec.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9AC0hM7rhd4"
      },
      "source": [
        "The most common mistake with `DictVectorizer` is calling `fit_transform` on test examples. This will wipe out the existing representation scheme, replacing it with one that matches the test examples. That will happen silently, but then you'll find that the new representations are incompatible with the model you fit. This is likely to manifest itself as a `ValueError` relating to feature counts. Here's an example that might help you spot this if and when it arises in your own work:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGzpMtW3rhd4",
        "outputId": "8a7a76ad-8583-469f-8a07-b9f7893a6297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ValueError: X has 4 features, but LogisticRegression is expecting 3 features as input.\n"
          ]
        }
      ],
      "source": [
        "toy_mod = LogisticRegression()\n",
        "\n",
        "vec = DictVectorizer(sparse=False)\n",
        "\n",
        "X_train = vec.fit_transform(train_feats)\n",
        "\n",
        "toy_mod.fit(X_train, [0, 1])\n",
        "\n",
        "# Here's the error! Don't use `fit_transform` again!\n",
        "# Use `transform`!\n",
        "X_test = vec.fit_transform(test_feats)\n",
        "\n",
        "try:\n",
        "    toy_mod.predict(X_test)\n",
        "except ValueError as err:\n",
        "    print(\"ValueError: {}\".format(err))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcg1Nv3Nrhd4"
      },
      "source": [
        "### Background: scikit-learn models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb9lnaU1rhd4"
      },
      "source": [
        "scikit-learn is an amazing package with, among many other things, an incredible array of classifier model implementations. We're going to use a simple softmax classifier for this homework question, but you will find that you can swap in essentially any scikit-learn classifier and see how it does."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ9mFJdarhd5"
      },
      "source": [
        "The core rhythm for scikit-learn models:\n",
        "\n",
        "1. Instantiate the model with any hyperparamters.\n",
        "2. `fit`\n",
        "3. `predict`\n",
        "\n",
        "Here's a quick example that also shows off scikit-learn's functionality for creating synthetic datasets and random train/test splits:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "g6nc5_tsrhd5"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_toy, y_toy = make_classification(\n",
        "    n_samples=200, n_classes=3,\n",
        "    n_informative=15, n_features=20,\n",
        "    weights=[0.2, 0.2, 0.6],\n",
        "    random_state=1)\n",
        "\n",
        "X_toy_train, X_toy_test, y_toy_train, y_toy_test = train_test_split(\n",
        "    X_toy, y_toy, test_size=0.20, stratify=y_toy, random_state=1)\n",
        "\n",
        "toymod = LogisticRegression(penalty='l2', C=1, fit_intercept=True)\n",
        "\n",
        "toymod.fit(X_toy_train, y_toy_train)\n",
        "\n",
        "toypreds = toymod.predict(X_toy_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2WQpc13rhd5"
      },
      "source": [
        "### Background: Classifier assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK6rk2g7rhd5"
      },
      "source": [
        "When assessing a classifier, the best first step is usually to get a classification report:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2m5ySGirhd5",
        "outputId": "f6d11f37-96be-4431-c93b-a719d02bb221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.444     0.500     0.471         8\n",
            "           1      0.444     0.500     0.471         8\n",
            "           2      0.909     0.833     0.870        24\n",
            "\n",
            "    accuracy                          0.700        40\n",
            "   macro avg      0.599     0.611     0.604        40\n",
            "weighted avg      0.723     0.700     0.710        40\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_toy_test, toypreds, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1ppTvdJrhd5"
      },
      "source": [
        "In this course, we will generally focus in the __macro-average F1 score__ (macro avg above). This is simply the mean of the per-class F1 scores, without any attention paid to the overall size of the class. This is our default because, in NLP, we tend to care about small classes as much as (often more than) large classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbW2Vmb1rhd6"
      },
      "source": [
        "The scikit-learn implementation of `macro_f1` can be finicky, so our course code provides a convenient wrapper:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "itjo-zJ_rhd6"
      },
      "outputs": [],
      "source": [
        "# import utils\n",
        "\n",
        "# utils.safe_macro_f1(y_toy_test, toypreds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf1m--_Trhd6"
      },
      "source": [
        "Note: scikit-learn models have a `score` method. For classifiers, this is set to use `accuracy` by default:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDeKiA58rhd6",
        "outputId": "d8ff6dc9-345a-4e16-b98f-5a475e684494"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "toymod.score(X_toy_test, y_toy_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8LQymZUrhd6"
      },
      "source": [
        "Accuracy generally isn't well-aligned with our goals, so we discourage use of this method (and of accuracy scores in general)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80in72fZrhd6"
      },
      "source": [
        "scikit-learn also makes it very easy to perform automatic hyperparameter tuning. A quick example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7s8v-UjJrhd7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {'C': (0.1, 0.2, 0.3), 'fit_intercept': [True, False]}\n",
        "\n",
        "toymod_tuned = LogisticRegression()\n",
        "\n",
        "clf = GridSearchCV(toymod_tuned, params, scoring='f1_macro')\n",
        "\n",
        "_ = clf.fit(X_toy, y_toy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLIswG8trhd7"
      },
      "source": [
        "Here's the best model found by this search:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "TuyJuVa-rhd7",
        "outputId": "690a3829-cb5e-420a-baef-7bfd010f0ae0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.3, fit_intercept=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.3, fit_intercept=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.3, fit_intercept=False)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "clf.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMrNomQmrhd7"
      },
      "source": [
        "Because we set `scoring='f1_macro'`, the above model was selected using our favored classifier scoring metric:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSUGICjwrhd7",
        "outputId": "b47b96ad-ff22-4529-d343-d2d532474155"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6943888670150135"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "clf.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7Skhlc7rhd8"
      },
      "source": [
        "With this best model in hand, we can perform our usual assessment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "LID3gfk1rhd8"
      },
      "outputs": [],
      "source": [
        "bestpreds = clf.best_estimator_.predict(X_toy_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FQxgvVwrheA",
        "outputId": "72183d62-59bd-40e3-d091-cf4f0718486b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.750     0.600     0.667        10\n",
            "           1      0.750     0.750     0.750         8\n",
            "           2      0.833     0.909     0.870        22\n",
            "\n",
            "    accuracy                          0.800        40\n",
            "   macro avg      0.778     0.753     0.762        40\n",
            "weighted avg      0.796     0.800     0.795        40\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(bestpreds, y_toy_test, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZstMXpyorheA"
      },
      "source": [
        "### Task 1: Feature functions [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioBYzr-1rheB"
      },
      "source": [
        "The tokenization scheme used by `unigrams_phi` is very basic and leads to unintuitive tokens with punctuation attached to them. Your task here is to complete `tweetgrams_phi`, which should lead to more intuitive results. The task is really just to use the NLTK [TweetTokenizer](https://www.nltk.org/api/nltk.tokenize.casual.html#nltk.tokenize.casual.TweetTokenizer) in place of the simple whitespace tokenization of `unigrams_phi` above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "GsoXMUI5rheB"
      },
      "outputs": [],
      "source": [
        "# Your `tweetgrams_phi` should tokenize data according to this tokenizer from NLTK:\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "def tweetgrams_phi(s, **kwargs):\n",
        "    \"\"\"The basis for a feature function using `TweetTokenizer`.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    s : str\n",
        "    kwargs : dict\n",
        "        Passed to `TweetTokenizer`\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Counter\n",
        "        A map from tokens to their counts in `text`\n",
        "\n",
        "    \"\"\"\n",
        "    # Cria√ß√£o de um objeto TweetTokenizer com argumentos opcionais\n",
        "    tokenizer = TweetTokenizer(**kwargs)\n",
        "\n",
        "    # Tokeniza√ß√£o da string usando o TweetTokenizer\n",
        "    tokens = tokenizer.tokenize(s)\n",
        "\n",
        "    # Contagem de ocorr√™ncias dos tokens\n",
        "    token_counts = Counter(tokens)\n",
        "\n",
        "    return token_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl07kGHMrheC"
      },
      "source": [
        "Here's a test you can use to check that your implementation is correct:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "aiotBgSprheC"
      },
      "outputs": [],
      "source": [
        "def test_tweetgrams_phi(func):\n",
        "    examples = [\n",
        "        (\n",
        "            \"Here's an example with an emoticon :)\",\n",
        "            Counter({'an': 2, \"Here's\": 1, 'example': 1, 'with': 1, 'emoticon': 1, ':)': 1})\n",
        "        ),\n",
        "        (\n",
        "            \"The URL is https://pytorch.org!\",\n",
        "            Counter({'The': 1, 'URL': 1, 'is': 1, 'https://pytorch.org': 1, '!': 1})\n",
        "        )\n",
        "    ]\n",
        "    errcount = 0\n",
        "    for ex, expected in examples:\n",
        "        result = func(ex, preserve_case=True)\n",
        "        if result != expected:\n",
        "            errcount += 1\n",
        "            print(f\"Error for `{func.__name__}`: For input {ex}, \"\n",
        "                  f\"expected {expected} but got {result}\")\n",
        "    caps_ex = \"CAPS\"\n",
        "    caps_result = func(caps_ex, preserve_case=False)\n",
        "    caps_expected = Counter({\"caps\": 1})\n",
        "    if caps_result != caps_expected:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: For input {caps_ex}, \"\n",
        "              f\"expected {caps_expected} but got {caps_result}\")\n",
        "    if errcount == 0:\n",
        "        print(f\"All tests passed for `{func.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW7rONvPrheC",
        "outputId": "f467dc34-d47b-4fd1-98f0-c2bd50d7be07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed for `tweetgrams_phi`\n"
          ]
        }
      ],
      "source": [
        "test_tweetgrams_phi(tweetgrams_phi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uIlGqZGJ8hR"
      },
      "source": [
        "### Task 2: Model training [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz2yG3yprheD"
      },
      "source": [
        "Your task is to complete `train_linear_model`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rtEaAkHtStQg"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "yfhADdcyJ8hR"
      },
      "outputs": [],
      "source": [
        "def train_linear_model(model, featfunc, train_dataset):\n",
        "    \"\"\"Train an sklearn classifier.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : sklearn classifier model\n",
        "    featfunc : func\n",
        "        Maps strings to Counter instances\n",
        "    train_dataset: dict\n",
        "        Must have a key \"sentence\" containing strings that `featfunc`\n",
        "        will process, and a key \"gold_label\" giving labels\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple\n",
        "        * A trained version of `model`\n",
        "        * A fitted `vectorizer` for the train set\n",
        "\n",
        "    \"\"\"\n",
        "    # Step 1: Featurize all the examples in `train_dataset['sentence']`\n",
        "    features = [featfunc(sentence) for sentence in train_dataset['sentence']]\n",
        "\n",
        "    # Step 2: Instantiate and use a `DictVectorizer`:\n",
        "    vectorizer = DictVectorizer(sparse=False)\n",
        "    X = vectorizer.fit_transform(features)\n",
        "\n",
        "    # Step 3: Train the model on the feature matrix and\n",
        "    # train_dataset['gold_label']:\n",
        "    X_train, x_test, y_train, y_test = train_test_split(X, train_dataset['gold_label'], random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Step 4: Return (model, vectorizer):\n",
        "    return model, vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D73TmHAOrheE"
      },
      "source": [
        "You can use the following test to help ensure that your implementation is correct:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "3qFE4pDGrheF"
      },
      "outputs": [],
      "source": [
        "def test_train_linear_model(func):\n",
        "    train_dataset = {\n",
        "        'sentence': ['A A', 'A B', 'B B', 'B A', 'B'],\n",
        "        'gold_label': [0, 1, 0, 1, 1]}\n",
        "    def featfunc(s):\n",
        "        return Counter(s.split())\n",
        "    model = LogisticRegression()\n",
        "    result = func(model, featfunc, train_dataset)\n",
        "    if not isinstance(result, tuple) or len(result) != 2:\n",
        "        print(f\"Error for `{func.__name__}`: Incorrect return type\")\n",
        "        return\n",
        "    model, vectorizer = result\n",
        "    if not hasattr(vectorizer, 'vocabulary_'):\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Second return value is not a trained vectorizer\")\n",
        "        return\n",
        "    if not hasattr(model, 'classes_'):\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"First return value is not a trained classifier\")\n",
        "        return\n",
        "    print(f\"No errors found for `{func.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NAAfo0ErheF",
        "outputId": "72b6fff8-6959-4eca-b747-af88bf86ff4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found for `train_linear_model`\n"
          ]
        }
      ],
      "source": [
        "_ = test_train_linear_model(train_linear_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXDROfiurheG"
      },
      "source": [
        "You can now very easily train models on our datasets. Quick example (this shouldn't take more than a couple of minutes to run even on a CPU):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "OQoCRRPHJ8hR"
      },
      "outputs": [],
      "source": [
        "# lr_unigrams, vec_unigrams = train_linear_model(\n",
        "#     LogisticRegression(max_iter=1000),\n",
        "#     unigrams_phi, dynasent_r1['train'])\n",
        "\n",
        "lr_unigrams, vec_unigrams = train_linear_model(\n",
        "    LogisticRegression(max_iter=1000),\n",
        "    unigrams_phi, pd.DataFrame(dynasent_r1['train']).sample(1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64yahIyQrheG"
      },
      "source": [
        "### Task 3: Model assessment [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJzfjGvZrheH"
      },
      "source": [
        "Having now trained a model, we'd like to perform assessments on new data. Your task is to complete the wrapper function `assess_linear_model` to do this. The primary things you need to put into practice are (1) how to use a trained vectorizer on new data and (2) how to make predictions with your trained model. (Both of these steps are reviewed earlier in this notebook.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "GKa7uOwYJ8hR"
      },
      "outputs": [],
      "source": [
        "def assess_linear_model(model, featfunc, vectorizer, assess_dataset):\n",
        "    \"\"\"Assess a trained sklearn model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: trained sklearn model\n",
        "    featfunc : func\n",
        "        Maps strings to count dicts\n",
        "    vectorizer : fitted DictVectorizer\n",
        "    assess_dataset: dict\n",
        "        Must have a key \"sentence\" containing strings that `featfunc`\n",
        "        will process, and a key \"gold_label\" giving labels\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    A classification report (multiline string)\n",
        "\n",
        "    \"\"\"\n",
        "    # Step 1: Featurize the assessment data\n",
        "    assess_features = [featfunc(sentence) for sentence in assess_dataset['sentence']]\n",
        "\n",
        "    # Step 2: Vectorize the assessment data features\n",
        "    X_assess = vectorizer.transform(assess_features)\n",
        "\n",
        "    # Step 3: Make predictions\n",
        "    predictions = model.predict(X_assess)\n",
        "\n",
        "    # Step 4: Return a classification report\n",
        "    return classification_report(assess_dataset['gold_label'], predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IayOt4wPrheH"
      },
      "source": [
        "Here's a quick test you can use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "eber9qb0rheI"
      },
      "outputs": [],
      "source": [
        "def test_assess_linear_model(assessfunc, trainfunc):\n",
        "    train_dataset = {\n",
        "        'sentence': ['A A', 'A B', 'B B', 'B A', 'A', 'B'],\n",
        "        'gold_label': [0, 1, 0, 1, 0, 1]}\n",
        "    assess_dataset = {\n",
        "        'sentence': ['A C', 'B A'],\n",
        "        'gold_label': [0, 1]}\n",
        "    def featfunc(s):\n",
        "        return Counter(s.split())\n",
        "    model = LogisticRegression()\n",
        "    model, vectorizer = trainfunc(model, featfunc, train_dataset)\n",
        "    result = assessfunc(model, featfunc, vectorizer, assess_dataset)\n",
        "    errcount = 0\n",
        "    if len(vectorizer.vocabulary_) != 2:\n",
        "        print(f\"Error for `{assessfunc.__name__}`: Unexpected feature count\")\n",
        "        errcount += 1\n",
        "    if 'weighted avg' not in result:\n",
        "        print(f\"Error for `{assessfunc.__name__}`: Unexpected return value\")\n",
        "        errcount += 1\n",
        "    if errcount == 0:\n",
        "        print(f\"No errors found for `{assessfunc.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYrMaqoXrheI",
        "outputId": "afa182c1-5884-48bb-a542-560c968e2442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found for `assess_linear_model`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "test_assess_linear_model(assess_linear_model, train_linear_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkkYQBX-rheJ"
      },
      "source": [
        "If you trained a model `lr_unigrams` above, you can now easily assess it. An example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buRd2jpYJ8hR",
        "outputId": "e4c63790-3109-4c63-bfdc-32e5a6d381d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.59      0.14      0.22      1200\n",
            "     neutral       0.40      0.84      0.55      1200\n",
            "    positive       0.51      0.34      0.41      1200\n",
            "\n",
            "    accuracy                           0.44      3600\n",
            "   macro avg       0.50      0.44      0.39      3600\n",
            "weighted avg       0.50      0.44      0.39      3600\n",
            "\n"
          ]
        }
      ],
      "source": [
        "report = assess_linear_model(\n",
        "    lr_unigrams,\n",
        "    unigrams_phi,\n",
        "    vec_unigrams,\n",
        "    dynasent_r1['validation'])\n",
        "\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezZAgHCNJ8hS"
      },
      "source": [
        "## Question 2: Transformer fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwFW4r_PrheK"
      },
      "source": [
        "We're now going to move into a more modern mode: fine-tuning pretrained components."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Te4hs7rheK"
      },
      "source": [
        "We'll use BERT-mini (originally from [the BERT repo](https://github.com/google-research/bert)) for the homework so that we can rapdily develop prototypes. You can then consider scaling up to larger models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "HIixC5g7rheK"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import AutoModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvBOuCX6rheL"
      },
      "source": [
        "The `transformers` library does a lot of logging. To avoid ending up with a cluttered notebook, I am changing the logging level. You might want to skip this as you scale up to building production systems, since the logging is very good ‚Äì it gives you a lot of insights into what the models and code are doing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "jmgQvV8wrheM"
      },
      "outputs": [],
      "source": [
        "transformers.logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRMZkCE3rheM"
      },
      "source": [
        "Here we set ourselves up to use BERT-mini:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "f1f5b070fb6544a9b4c4980a5bd6e6f9",
            "9220defbb3544051b74f0d07854dc8d7",
            "cd582805b131443ab8a6a2842430645f",
            "535adcd46c7f4b14bc2ddbacc088c724",
            "60e3ff4bd2aa4a3184c777a23288ba4a",
            "3a5548839c6c45729f52930d18e68e56",
            "0288a9cdcbb74083b0dcebf8e288b72e",
            "9e076bd12edf47e29a085fcbfe52a835",
            "6c3448313a8942f998a7a54ba70b0de8",
            "f2154c56dd8247d884cc451f6b727d8a",
            "68017290120e4b258e1e5ef72804cbba",
            "10fe45885b6d4ea5b50362daa4d0f91f",
            "30fc6416b018456a98e32c840e944867",
            "e76c07a5b928463787291ba3139417c6",
            "a199011b492e4b88b509325596aa4632",
            "f5cb83bf8fa24ac4bc7d2323f1fc8504",
            "e1ed63cb836d4d20a8c7cf4ffab66a00",
            "717a48fc3a1846a78bafef4da36bb1d3",
            "c440c490e990454e8bc6df3941a5a77a",
            "5e3b84b4a9574aa8b3ad68e356972394",
            "8d1c8b9e4671478ca0025ce9e3570f87",
            "a4272638faf14f76b14e1f72068436d9",
            "f3a7504fb7344764889b71117a80c93d",
            "5242328f94eb435d9a023d1cdc4800f8",
            "ebf8bceb2d59487587b552ea383f8aef",
            "f2934afa462c42d9b0b954e6a7f7dc10",
            "5c850eb5df8746b185e94e022f02fe0a",
            "19767ba3fd12467da326ca80104d0c37",
            "92b86fd37fd74dba95358cda1f7d0e83",
            "9d98c57f75034ac3bb8d5f99b886d49e",
            "7e4073838b2b4c8ab1534da052dd57be",
            "3204d22746d24370ab18b9f5f62b47bf",
            "cd79d4c3e1d0400f8508fbc6dca73222"
          ]
        },
        "id": "6wbwx9FNrheM",
        "outputId": "2ee2b941-f8b1-45eb-df6b-683c26758833"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/286 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1f5b070fb6544a9b4c4980a5bd6e6f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/45.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10fe45885b6d4ea5b50362daa4d0f91f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3a7504fb7344764889b71117a80c93d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "weights_name = \"prajjwal1/bert-mini\"\n",
        "\n",
        "bert = AutoModel.from_pretrained(weights_name)\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(weights_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ind3pD8ArheN"
      },
      "source": [
        "### Background: Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6JbSGSTrheN"
      },
      "source": [
        "Tokenization in Transformer models is handled differently from tokenization in linear models of the sort we used in Question 1. For Transformer models, we need to use the tokenizer that comes with the model so that we reliably have embedding representations for every token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ITMeBZItrheN"
      },
      "outputs": [],
      "source": [
        "example_text = \"Bert knows Snuffleupagus\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYb_4EW8rheO"
      },
      "source": [
        "Here's a basic tokenization step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YALuG7HyrheO",
        "outputId": "23999bb0-0a71-4729-c78f-bbbddad1f1d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bert', 'knows', 's', '##nu', '##ffle', '##up', '##ag', '##us']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "bert_tokenizer.tokenize(example_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVbHKzmqrheO"
      },
      "source": [
        "Notice that the tokenizer split \"Snuffleupagus\" into a bunch of subword tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qAA-3uFrheO"
      },
      "source": [
        "The above use of the tokenizer, where we map from strings to lists of strings, is really for us humans. For modeling, the most important step for tokenization is mapping individual strings to sequences of integer ids. These ids key into the lowest embedding layer of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxctSs8urheP",
        "outputId": "7ed54403-44a5-4cd9-af5c-7c192d6900eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 14324, 4282, 1055, 11231, 18142, 6279, 8490, 2271, 102]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "ex_ids = bert_tokenizer.encode(example_text, add_special_tokens=True)\n",
        "ex_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnC93n42rheP"
      },
      "source": [
        "We can get map these indices back to \"words\" if we want:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G074dj_grheQ",
        "outputId": "2af65c22-dfaa-4cd8-95c8-64bb20b431b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'bert',\n",
              " 'knows',\n",
              " 's',\n",
              " '##nu',\n",
              " '##ffle',\n",
              " '##up',\n",
              " '##ag',\n",
              " '##us',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "bert_tokenizer.convert_ids_to_tokens(ex_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOPGZqkIrheQ"
      },
      "source": [
        "### Background: Representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXLdLkmvrheQ"
      },
      "source": [
        "Having mapped our string to a list of tokens, we can use the `forward` method of the model to get representations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "6ubLn1JurheT"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    reps = bert(torch.tensor([ex_ids]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUQ64l3arheT"
      },
      "source": [
        "There are a lot of options for which representations to get. With the above call, we got the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1EWVBD9rheV",
        "outputId": "f0664f40-d121-49ce-e97a-d6e655e2b0e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['last_hidden_state', 'pooler_output'])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "reps.keys()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reps[\"last_hidden_state\"]"
      ],
      "metadata": {
        "id": "D-kjZ0x96LwP",
        "outputId": "fec1bdea-9f35-41b5-9b3e-965f575b3b9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.3763, -0.3209,  0.8817,  ...,  0.2445, -1.0252, -0.0538],\n",
              "         [-0.8892, -0.0093,  0.8197,  ..., -0.6787, -0.9723, -0.4417],\n",
              "         [-1.3524,  0.9359,  0.6495,  ...,  0.1472, -0.8518, -0.6356],\n",
              "         ...,\n",
              "         [-0.1138,  1.8002, -0.1366,  ...,  0.6392, -0.1475, -0.3307],\n",
              "         [-1.0193,  1.0466,  0.9183,  ...,  0.5956, -0.7098, -0.8501],\n",
              "         [ 0.0236, -0.0071,  1.1606,  ...,  0.1107, -0.9056,  0.2857]]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reps[\"pooler_output\"]"
      ],
      "metadata": {
        "id": "X9bfacUb6LzG",
        "outputId": "a65b0564-96b1-4ec2-8b15-e3a8c15dd953",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-9.2290e-01,  1.0230e-01, -9.3431e-01, -6.3901e-01,  1.2526e-01,\n",
              "          9.5915e-01,  3.0689e-02, -1.4967e-01,  2.5343e-02,  9.9048e-01,\n",
              "          2.1507e-01,  9.9986e-01, -9.9997e-01, -6.8690e-01,  6.9094e-01,\n",
              "          1.5442e-01,  9.8188e-01, -9.2389e-01,  9.4279e-01, -9.9466e-01,\n",
              "         -1.0000e+00,  2.9478e-01,  9.8790e-01, -9.8509e-01,  9.7754e-01,\n",
              "          9.2691e-01,  9.5539e-02,  4.2452e-01,  9.9200e-01, -1.8437e-01,\n",
              "         -9.9407e-01, -9.7253e-02,  9.9589e-01, -9.8994e-01, -9.9086e-01,\n",
              "         -7.4146e-01, -2.6583e-01,  9.8376e-01, -6.9529e-01,  4.4316e-01,\n",
              "          5.6662e-01, -9.9790e-01, -1.0513e-01,  9.9653e-01,  9.9994e-01,\n",
              "          2.1554e-01,  1.7601e-01,  9.9386e-01,  1.4030e-02, -3.0939e-02,\n",
              "         -7.6117e-01, -2.5482e-01, -4.0483e-02,  9.9971e-01, -8.9593e-01,\n",
              "         -9.5623e-01,  9.9361e-01,  8.5711e-01, -1.3484e-01, -9.7980e-01,\n",
              "         -9.9809e-01,  9.9867e-01,  9.9593e-01, -7.4216e-01,  5.4635e-01,\n",
              "         -7.1575e-01, -9.2153e-02, -9.3266e-01, -5.3709e-01,  2.1345e-02,\n",
              "         -1.0718e-02,  1.3519e-01, -9.3059e-01,  9.3918e-01,  6.1588e-01,\n",
              "         -9.0231e-01,  9.9504e-01,  4.3140e-03,  9.9602e-01,  8.9800e-01,\n",
              "         -9.5170e-01, -4.7025e-02,  1.1787e-01, -1.6665e-01, -1.6423e-02,\n",
              "         -9.9344e-01,  1.4235e-01,  9.9981e-01, -3.6268e-01, -9.3539e-01,\n",
              "          9.8879e-01, -9.5316e-01,  6.5017e-01, -6.0914e-02, -9.8945e-01,\n",
              "         -6.1620e-01,  3.1320e-02, -4.8196e-01,  9.9480e-01,  6.4073e-02,\n",
              "         -7.5434e-01, -9.7609e-01, -2.4788e-01,  8.9608e-01, -5.8748e-01,\n",
              "          1.2908e-01, -9.9881e-01, -8.8003e-01,  1.3074e-01,  2.0527e-01,\n",
              "         -3.2273e-01,  1.1962e-01,  7.3380e-02, -1.0837e-01, -7.8290e-02,\n",
              "         -5.3368e-02,  8.7695e-01, -5.5681e-01, -9.8403e-01,  1.3202e-01,\n",
              "         -9.9260e-01, -9.9724e-01, -4.5571e-02,  9.9017e-01,  9.9297e-01,\n",
              "         -6.4924e-03, -9.7725e-01, -9.7488e-01, -2.1966e-01, -1.5135e-01,\n",
              "         -1.4807e-01,  1.1426e-01,  2.7110e-01,  9.8750e-01,  2.9346e-01,\n",
              "         -9.4146e-01, -9.6002e-01,  7.1434e-01, -9.6677e-01, -2.9888e-02,\n",
              "          6.6484e-01, -2.3480e-01,  3.0372e-01, -9.0517e-01,  9.8183e-01,\n",
              "         -8.3354e-01, -9.9932e-01,  9.9997e-01,  9.9859e-01, -9.3859e-01,\n",
              "          9.9306e-01, -5.9194e-01, -9.9745e-01,  3.1038e-01, -9.8571e-01,\n",
              "         -4.9018e-02,  9.9599e-01,  2.1445e-01, -9.4612e-01,  8.2699e-01,\n",
              "         -9.9986e-01, -9.4045e-01,  8.8219e-01, -8.3888e-01, -9.8657e-01,\n",
              "         -8.4266e-01, -2.7084e-01, -4.6668e-02, -9.8809e-01,  2.1356e-01,\n",
              "         -9.9204e-01,  6.0848e-01, -6.8483e-01, -4.7140e-04,  6.1108e-02,\n",
              "         -1.2110e-01,  9.6001e-01, -4.0085e-01, -2.2275e-02, -8.3849e-02,\n",
              "          9.6998e-01,  2.5638e-02, -1.7925e-01, -9.7125e-01,  9.9880e-01,\n",
              "         -5.1816e-01,  9.9867e-01,  9.9247e-01,  1.8498e-01,  5.6781e-01,\n",
              "         -1.7333e-01,  9.9937e-01,  6.4199e-01, -9.8797e-01, -4.4958e-02,\n",
              "          9.9845e-01, -1.6508e-01,  3.2759e-01,  8.9644e-01, -1.0914e-01,\n",
              "          9.9070e-01, -8.8307e-01, -9.3527e-01,  9.9956e-01,  9.6370e-01,\n",
              "          9.9901e-01, -8.9800e-01, -9.4352e-01, -9.4038e-01,  9.9696e-01,\n",
              "         -5.7409e-01,  8.1687e-01,  9.5796e-01, -9.8249e-01, -9.2919e-01,\n",
              "         -2.3418e-02,  9.9943e-01, -8.6192e-01,  8.9046e-01,  9.8100e-01,\n",
              "          1.4863e-01, -9.9991e-01, -9.9946e-01, -2.7628e-01,  9.9970e-01,\n",
              "          6.1216e-01,  8.2845e-01, -2.0103e-01,  9.9521e-01, -1.0274e-01,\n",
              "          9.6879e-01,  9.5949e-01,  7.5172e-01,  9.9978e-01, -9.9896e-01,\n",
              "          5.6899e-02,  8.0609e-01, -5.9859e-02,  8.3742e-02, -1.7489e-01,\n",
              "          9.8543e-01,  9.9995e-01,  2.1832e-01,  2.2454e-01,  9.6608e-01,\n",
              "          9.9924e-01, -9.9897e-01, -1.0471e-02, -7.9151e-01, -9.9991e-01,\n",
              "         -2.0001e-01,  9.9371e-01, -7.9080e-01, -2.6725e-01,  5.9701e-01,\n",
              "          7.0279e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohJ3120rrheV"
      },
      "source": [
        "The value of `last_hidden_state` hidden state is the sequence of final output states from the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULRt2j42rheW",
        "outputId": "d7b669dd-d27f-449f-ef22-73e26300e188"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "reps.last_hidden_state.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nMPFqdDrheW"
      },
      "source": [
        "This is: 1 example, 10 token representations, each one a 256 dimension vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh1xDf5BrheX"
      },
      "source": [
        "The value of `pooler_output` is a set of currently random parameters sitting on top of the first output hidden state. You can see here that it is a single vector representation per example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qATgD45frheX",
        "outputId": "6d56eeb3-9fc5-4360-d2cc-e97846ad4474"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "reps.pooler_output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_tDYA-mrheX"
      },
      "source": [
        "I often feel unsure of precisely what this model component is. Here we can have a quick look:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17ZjeHISrheX",
        "outputId": "e1d98ecb-ffc6-4bce-ad31-21fafab1611d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertPooler(\n",
              "  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (activation): Tanh()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "bert.pooler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLUS2xoYrheY"
      },
      "source": [
        "So this is a dense linear layer (a single matrix of weights) with a bias term, and a tanh activation function is applied to the output. We could put a classifier head on top of this if we wanted to, but we might have mixed feelings about being stuck with that tanh step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-AO_KWtrheY"
      },
      "source": [
        "### Background: Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siO-CuTorheY"
      },
      "source": [
        "Where examples from a single batch have different lengths, we need to mask the padded tokens to get the intended results from the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZFESb58rheY"
      },
      "source": [
        "For a quick example, here we process our full example from above and print out the first five values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTXE052mrheZ",
        "outputId": "e869ab90-63a5-4036-9dd0-f5b299796eeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.3763, -0.3209,  0.8817,  0.4568, -1.0314])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    reps = bert(torch.tensor([ex_ids]))\n",
        "    print(reps.last_hidden_state[0][0][: 5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTPrVh1Erhep"
      },
      "source": [
        "And now we do the same thing, but with masking of the final five positions to illustate:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm7wPDYvrhep",
        "outputId": "67b95b2f-9d6a-491b-e21e-97e84687b669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.1793, -0.8994,  0.9695,  0.9130, -0.7129])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    # Mask the last 5 tokens:\n",
        "    am = torch.tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])\n",
        "    maskreps = bert(torch.tensor([ex_ids]), attention_mask=am)\n",
        "    print(maskreps.last_hidden_state[0][0][: 5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flXrHMwOrheq"
      },
      "source": [
        "### Task 1: Batch tokenization [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buGo1v_8rheq"
      },
      "source": [
        "Your task here is to use the `batch_encode_plus` method for `bert_tokenizer` to tokenize a list of strings. You should complete `get_batch_token_ids` according to the specification in the doctring. All these steps can be handled with a single call to `batch_encode_plus`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "CGw8B76Wrheq"
      },
      "outputs": [],
      "source": [
        "def get_batch_token_ids(batch, tokenizer):\n",
        "    \"\"\"Map `batch` to a tensor of ids. The return\n",
        "    value should meet the following specification:\n",
        "\n",
        "    1. The max length should be 512.\n",
        "    2. Examples longer than the max length should be truncated\n",
        "    3. Examples should be padded to the max length for the batch.\n",
        "    4. The special [CLS] should be added to the start and the special\n",
        "       token [SEP] should be added to the end.\n",
        "    5. The attention mask should be returned\n",
        "    6. The return value of each component should be a tensor.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    batch: list of str\n",
        "    tokenizer: Hugging Face tokenizer\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict with at least \"input_ids\" and \"attention_mask\" as keys,\n",
        "    each with Tensor values\n",
        "\n",
        "    \"\"\"\n",
        "    # Tokenizar o batch e obter os IDs\n",
        "    tokenized_batch = tokenizer.batch_encode_plus(\n",
        "        batch,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=512,\n",
        "        return_tensors='pt',  # Retornar tensores PyTorch\n",
        "        return_attention_mask=True,\n",
        "        add_special_tokens=True,  # Adicionar [CLS] e [SEP]\n",
        "    )\n",
        "\n",
        "    # Retornar um dicion√°rio com os IDs e a m√°scara de aten√ß√£o\n",
        "    return {\n",
        "        \"input_ids\": tokenized_batch[\"input_ids\"],\n",
        "        \"attention_mask\": tokenized_batch[\"attention_mask\"]\n",
        "    }\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqSGcIWnrher"
      },
      "source": [
        "Here's a test you can use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "powkj1lBrher"
      },
      "outputs": [],
      "source": [
        "def test_get_batch_token_ids(func):\n",
        "    examples = [\n",
        "        \"Bert knows Snuffleupagus\",\n",
        "        \"ELMo knew Bert.\",\n",
        "        \"Buffalo \" * 520\n",
        "    ]\n",
        "    test_tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-mini\")\n",
        "    result = func(examples, test_tokenizer)\n",
        "    errcount = 0\n",
        "    if 'attention_mask' not in result:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Attention mask was not returned\")\n",
        "    ids = result['input_ids']\n",
        "    if not isinstance(ids, torch.Tensor):\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Return values are not tensors\")\n",
        "    if ids.shape[1] != 512:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Expected sequence length 512; got {ids.shape[1]}\")\n",
        "    if ids[0][0] != bert_tokenizer.cls_token_id:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Special tokens were not added\")\n",
        "    if errcount == 0:\n",
        "        print(f\"No errors found for `{func.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2JSSfnvrher",
        "outputId": "48143ebb-2aad-4c32-f32b-277a3ecf1056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found for `get_batch_token_ids`\n"
          ]
        }
      ],
      "source": [
        "test_get_batch_token_ids(get_batch_token_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQAu3zKVrher"
      },
      "source": [
        "### Task 2: Contextual representations [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI1Xku2arhes"
      },
      "source": [
        "This next task is not used directly in fine-tuning, but it should help ensure that you understand how BERT representations are created and how they need to be managed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFNZLK-2rhes"
      },
      "source": [
        "Your task is to complete `get_reps` so that, given a dataset (list of strings), it returns a single tensor in which each row is the output hidden state above the [CLS] token for that example. `gets_reps` has a batchsize argument that the user can manage depending on how much available memory they have and how large their model is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "76t6yCearhes"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def get_reps(dataset, model, tokenizer, batchsize=20):\n",
        "    \"\"\"Represent each example in `dataset` with the final hidden state\n",
        "    above the [CLS] token.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset : list of str\n",
        "    model : BertModel\n",
        "    tokenizer : BertTokenizerFast\n",
        "    batchsize : int\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor with shape `(n_examples, dim)` where `dim` is the\n",
        "    dimensionality of the representations for `model`\n",
        "\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    with torch.no_grad():\n",
        "        # Iterate over `dataset` in batches:\n",
        "        for i in range(0, len(dataset), batchsize):\n",
        "            # Extract a batch\n",
        "            batch = dataset[i:i + batchsize]\n",
        "\n",
        "            # Encode the batch with `get_batch_token_ids`:\n",
        "            token_ids_result = get_batch_token_ids(batch, tokenizer)\n",
        "\n",
        "            # Get the representations from the model, making\n",
        "            # sure to pay attention to masking:\n",
        "            outputs = model(**token_ids_result, return_dict=True)\n",
        "            last_hidden_states = outputs.last_hidden_state\n",
        "\n",
        "            # Extract the [CLS] token representations\n",
        "            cls_token_reps = last_hidden_states[:, 0, :]  # [0] is the index of [CLS]\n",
        "\n",
        "            # Append to the data list\n",
        "            data.append(cls_token_reps)\n",
        "\n",
        "        # Concatenate the representations from all batches\n",
        "        representations = torch.cat(data, dim=0)\n",
        "\n",
        "    return representations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV_kbF37rhet"
      },
      "source": [
        "Quick test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "NFJBnKuarhet"
      },
      "outputs": [],
      "source": [
        "def test_get_reps(func):\n",
        "    examples = [\"The cat slept.\", \"The bird chirped.\"] * 20\n",
        "    weights_name = \"prajjwal1/bert-mini\"\n",
        "    test_model = AutoModel.from_pretrained(weights_name)\n",
        "    test_tokenizer = AutoTokenizer.from_pretrained(weights_name)\n",
        "    result = func(examples, test_model, test_tokenizer, batchsize=2)\n",
        "    errcount = 0\n",
        "    if result.shape != (40, 256):\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Expected shape {(40, 256)}, got {result.shape}\")\n",
        "    if round(result[0][0].item(), 2) != -0.64:\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Representations seem to be incorrect\")\n",
        "    print(f\"No errors found for `{func.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpT-Uok-rhet",
        "outputId": "746cc61b-786a-4b84-974b-ce911b770934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found for `get_reps`\n"
          ]
        }
      ],
      "source": [
        "test_get_reps(get_reps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSkjF62lrhet"
      },
      "source": [
        "### Task 3: Fine-tuning module [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPefyJbLrheu"
      },
      "source": [
        "We can now put the above together into a basic `nn.Module` that will fine-tune our BERT model. Most of the module is written for you. The pieces you need to implement:\n",
        "\n",
        "1. in the `init` methid, define `self.classifier_layer` using [nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)\n",
        "2. Complete the `forward` method.\n",
        "\n",
        "Precise instructions are provided in the docstrings for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "DI_llzyUJ8hS"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "class BertClassifierModule(nn.Module):\n",
        "    def __init__(self,\n",
        "            n_classes,\n",
        "            hidden_activation,\n",
        "            weights_name=\"prajjwal1/bert-mini\"):\n",
        "        \"\"\"This module loads a Transformer based on  `weights_name`,\n",
        "        puts it in train mode, add a dense layer with activation\n",
        "        function give by `hidden_activation`, and puts a classifier\n",
        "        layer on top of that as the final output. The output of\n",
        "        the dense layer should have the same dimensionality as the\n",
        "        model input.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_classes : int\n",
        "            Number of classes for the output layer\n",
        "        hidden_activation : torch activation function\n",
        "            e.g., nn.Tanh()\n",
        "        weights_name : str\n",
        "            Name of pretrained model to load from Hugging Face\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.n_classes = n_classes\n",
        "        self.weights_name = weights_name\n",
        "        self.bert = AutoModel.from_pretrained(self.weights_name)\n",
        "        self.bert.train()\n",
        "        self.hidden_activation = hidden_activation\n",
        "        self.hidden_dim = self.bert.embeddings.word_embeddings.embedding_dim\n",
        "        # Add the new parameters here using `nn.Sequential`.\n",
        "        # We can define this layer as\n",
        "        #\n",
        "        #  h = f(cW1 + b_h)\n",
        "        #  y = hW2 + b_y\n",
        "        #\n",
        "        # where c is the final hidden state above the [CLS] token,\n",
        "        # W1 has dimensionality (self.hidden_dim, self.hidden_dim),\n",
        "        # W2 has dimensionality (self.hidden_dim, self.n_classes),\n",
        "        # f is the hidden activation, and we rely on the PyTorch loss\n",
        "        # function to add apply a softmax to y.\n",
        "        self.classifier_layer = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "            self.hidden_activation,\n",
        "            nn.Linear(self.hidden_dim, self.n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, indices, mask):\n",
        "        \"\"\"Process `indices` with `mask` by feeding these arguments\n",
        "        to `self.bert` and then feeding the initial hidden state\n",
        "        in `last_hidden_state` to `self.classifier_layer`\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        indices : tensor.LongTensor of shape (n_batch, k)\n",
        "            Indices into the `self.bert` embedding layer. `n_batch` is\n",
        "            the number of examples and `k` is the sequence length for\n",
        "            this batch\n",
        "        mask : tensor.LongTensor of shape (n_batch, d)\n",
        "            Binary vector indicating which values should be masked.\n",
        "            `n_batch` is the number of examples and `k` is the\n",
        "            sequence length for this batch\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        tensor.FloatTensor\n",
        "            Predicted values, shape `(n_batch, self.n_classes)`\n",
        "\n",
        "        \"\"\"\n",
        "        # Forward pass through BERT\n",
        "        outputs = self.bert(input_ids=indices, attention_mask=mask, return_dict=True)\n",
        "        last_hidden_state = outputs.last_hidden_state\n",
        "\n",
        "        # Extract representations for [CLS] token\n",
        "        cls_token_reps = last_hidden_state[:, 0, :]\n",
        "\n",
        "        # Forward pass through the classifier layer\n",
        "        predictions = self.classifier_layer(cls_token_reps)\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "9hXXB2yCrheu"
      },
      "outputs": [],
      "source": [
        "bert_module = BertClassifierModule(n_classes=3, hidden_activation=nn.Tanh())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AO-QRTBgrhev",
        "outputId": "92cbd264-67aa-476a-925c-3a54f1b723bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3385, -0.0871, -0.1264],\n",
              "        [-0.0165, -0.2797,  0.0331]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "ids = get_batch_token_ids(\n",
        "    dynasent_r1['train']['sentence'][: 2],\n",
        "    bert_tokenizer)\n",
        "\n",
        "bert_module(ids['input_ids'], ids['attention_mask'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "OylzLZUIrhev"
      },
      "outputs": [],
      "source": [
        "def test_bert_classifier_module(moduleclass):\n",
        "    expected_out = 5\n",
        "    expected_hidden = 256\n",
        "    expected_activation = nn.ReLU()\n",
        "    mod = moduleclass(expected_out, expected_activation)\n",
        "    errcount = 0\n",
        "\n",
        "    # Basic layer structure:\n",
        "    if not hasattr(mod, \"classifier_layer\") or mod.classifier_layer is None:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{moduleclass.__name__}`: \"\n",
        "              f\"Missing attribute `classifier_layer`\")\n",
        "        return\n",
        "    for i in range(3):\n",
        "        try:\n",
        "            bert_module.classifier_layer[i]\n",
        "        except IndexError:\n",
        "            errcount += 1\n",
        "            print(f\"Error for `{moduleclass.__name__}`: \"\n",
        "                  f\"`classifier_layer` is not an `nn.Sequential` \"\n",
        "                  f\"and/or does not have the right structure\")\n",
        "    # Correct first layer dimensionality:\n",
        "    result_hidden = mod.classifier_layer[0].out_features\n",
        "    if result_hidden != expected_hidden:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{moduleclass.__name__}`: \"\n",
        "              f\"Expected `classifier_layer` hidden dim {expected_hidden}, \"\n",
        "              f\"got {result_hidden}\")\n",
        "    # Correct activation:\n",
        "    result_activation = mod.classifier_layer[1].__class__.__name__\n",
        "    if result_activation != expected_activation.__class__.__name__:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{moduleclass.__name__}`: \"\n",
        "              f\"Incorrect hidden activation\")\n",
        "    # Correct output dimensionality:\n",
        "    result_out = mod.classifier_layer[2].out_features\n",
        "    if result_out != expected_out:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{moduleclass.__name__}`: \"\n",
        "              f\"Expected `classifier_layer` out dim {expected_out}, \"\n",
        "              f\"got {result_out}\")\n",
        "    # forward method:\n",
        "    ids = get_batch_token_ids([\"A B C\", \"A B\"], bert_tokenizer)\n",
        "    result = mod(ids['input_ids'], ids['attention_mask'])\n",
        "    if result.shape != (2, 5):\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{moduleclass.__name__}`: \"\n",
        "              f\"Expected output shape {(2, 5)}, got {result.shape}\")\n",
        "    if errcount == 0:\n",
        "        print(f\"No errors found for `{moduleclass.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muTr1vhtrhev",
        "outputId": "62f426cf-6627-44de-ddf9-a3b0adb2b4bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found for `BertClassifierModule`\n"
          ]
        }
      ],
      "source": [
        "test_bert_classifier_module(BertClassifierModule)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM6mRVcrrhev"
      },
      "source": [
        "### Optional use: Classifier interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x1SwsCErhew"
      },
      "source": [
        "The above module doesn't have functionality for processing data and fitting models. Our course code includes some general purpose code for adding these features. Here is an example that should work well with the module you wrote above. For more details on the design of these interfaces, see [tutorial_pytorch_models.ipynb](tutorial_pytorch_models.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "rfD8yC4AJ8hT"
      },
      "outputs": [],
      "source": [
        "# from torch_shallow_neural_classifier import TorchShallowNeuralClassifier\n",
        "\n",
        "# class BertClassifier(TorchShallowNeuralClassifier):\n",
        "#     def __init__(self, weights_name, *args, **kwargs):\n",
        "#         self.weights_name = weights_name\n",
        "#         self.tokenizer = AutoTokenizer.from_pretrained(self.weights_name)\n",
        "#         super().__init__(*args, **kwargs)\n",
        "#         self.params += ['weights_name']\n",
        "\n",
        "#     def build_graph(self):\n",
        "#         return BertClassifierModule(\n",
        "#             self.n_classes_, self.hidden_activation, self.weights_name)\n",
        "\n",
        "#     def build_dataset(self, X, y=None):\n",
        "#         data = get_batch_token_ids(X, self.tokenizer)\n",
        "#         if y is None:\n",
        "#             dataset = torch.utils.data.TensorDataset(\n",
        "#                 data['input_ids'], data['attention_mask'])\n",
        "#         else:\n",
        "#             self.classes_ = sorted(set(y))\n",
        "#             self.n_classes_ = len(self.classes_)\n",
        "#             class2index = dict(zip(self.classes_, range(self.n_classes_)))\n",
        "#             y = [class2index[label] for label in y]\n",
        "#             y = torch.tensor(y)\n",
        "#             dataset = torch.utils.data.TensorDataset(\n",
        "#                 data['input_ids'], data['attention_mask'], y)\n",
        "#         return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB9qecZyrhe1"
      },
      "source": [
        "And here is a training run that should do pretty well for our problem.\n",
        "\n",
        "__Note__: This step should not be run on CPU machines. On Google Colab with a GPU, it will likely take about an hour."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "re8lzSepJ8hT"
      },
      "outputs": [],
      "source": [
        "# bert_finetune = BertClassifier(\n",
        "#     weights_name=\"prajjwal1/bert-mini\",\n",
        "#     hidden_activation=nn.ReLU(),\n",
        "#     eta=0.00005,          # Low learning rate for effective fine-tuning.\n",
        "#     batch_size=8,         # Small batches to avoid memory overload.\n",
        "#     gradient_accumulation_steps=4,  # Increase the effective batch size to 32.\n",
        "#     early_stopping=True,  # Early-stopping\n",
        "#     n_iter_no_change=5)   # params."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "wlvq0G-PJ8hT"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "\n",
        "# _ = bert_finetune.fit(\n",
        "#     dynasent_r1['train']['sentence'],\n",
        "#     dynasent_r1['train']['gold_label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "WwwiIuKqJ8hT"
      },
      "outputs": [],
      "source": [
        "# preds = bert_finetune.predict(sst['validation']['sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "q3Af7RAOJ8hT"
      },
      "outputs": [],
      "source": [
        "# print(classification_report(sst['validation']['gold_label'], preds, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOblLwl3J8hU"
      },
      "outputs": [],
      "source": [
        "# preds = bert_finetune.predict(dynasent_r1['validation']['sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "ndDbPLY1b7lj"
      },
      "outputs": [],
      "source": [
        "# print(classification_report(dynasent_r1['validation']['gold_label'], preds, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f5dBu3Zrhe3"
      },
      "source": [
        "## Question 3: Your original system [3 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3nLApXSrhe3"
      },
      "source": [
        "Your task is to develop an original ternary sentiment classifier model. There are many options. The only rule:\n",
        "\n",
        "__You cannot make any use of the test sets for DynaSent-R1, DynaSent-R2, or SST-3, at any time during the course of development.__\n",
        "\n",
        "The integrity of the bakeoff depends on this rule being followed.\n",
        "\n",
        "It's fine to use the dev sets for system development ‚Äì indeed, we encourage this.\n",
        "\n",
        "For system development, here are some relatively manageable ideas that you might try:\n",
        "\n",
        "* Different pretrained models. There are many models available on the [Hugging Face models hub](https://huggingface.co/models) that will be drop-in replacements for BERT-mini as we used it above.\n",
        "\n",
        "* Different fine-tuning regimes. We used the [CLS] token above. This doesn't make especially good use of the output states of the models. Pooling across these representtions (with sum, average, etc.) is likely to be better.\n",
        "\n",
        "* Different training regimes. You have three train sets at your disposal, and there may be other sentiment datasets that could contribute to making your system more robust in new domains.\n",
        "\n",
        "* Entirely different approaches. There is no requirement that you make use of any of the concepts from the homework questions in constructing your original system. Anything goes as long as you follow the one rule given above in bold.\n",
        "\n",
        "We want to emphasize that this needs to be an original system. It doesn't suffice to download code from the Web, retrain, and submit. You can build on others' code, but you have to do something new and meaningful with it. See the course website for additional guidance on how original systems will be evaluated.\n",
        "\n",
        "In the cell below, please provide a brief technical description of your original system, so that the teaching team can gain an understanding of what it does. This will help us to understand your code and analyze all the submissions to identify patterns and strategies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ucv4-m6rhe4"
      },
      "outputs": [],
      "source": [
        "# PLEASE MAKE SURE TO INCLUDE THE FOLLOWING BETWEEN THE START AND STOP COMMENTS:\n",
        "#   1) Textual description of your system.\n",
        "#   2) The code for your original system.\n",
        "# PLEASE MAKE SURE NOT TO DELETE OR EDIT THE START AND STOP COMMENTS\n",
        "\n",
        "# START COMMENT: Enter your system description in this cell.\n",
        "\n",
        "\n",
        "# STOP COMMENT: Please do not remove this comment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69kgqadIrhe4"
      },
      "source": [
        "## Question 4: Bakeoff entry [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VTWGh0xrhe4"
      },
      "source": [
        "The bakeoff dataset is available at\n",
        "\n",
        "https://web.stanford.edu/class/cs224u/data/cs224u-sentiment-test-unlabeled.csv\n",
        "\n",
        "This code should grab it for you and put it in `data/sentiment` if you are working in the cloud:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqCLm6FRrhe5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(os.path.join(\"data\", \"sentiment\", \"cs224u-sentiment-test-unlabeled.csv\")):\n",
        "    !mkdir -p data/sentiment\n",
        "    !wget https://web.stanford.edu/class/cs224u/data/cs224u-sentiment-test-unlabeled.csv -P data/sentiment/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLoxz9f1rhe5"
      },
      "source": [
        "If the above fails, you can just download the file and place it in `data/sentiment`."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RdLcJJgw9cfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY2zcfGDrhe5"
      },
      "source": [
        "Once you have the file, you can load it to a `pd.DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0919Ao8prhe6"
      },
      "outputs": [],
      "source": [
        "bakeoff_df = pd.read_csv(\n",
        "    os.path.join(\"data\", \"sentiment\", \"cs224u-sentiment-test-unlabeled.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vXuQSJwrhe6"
      },
      "outputs": [],
      "source": [
        "bakeoff_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMXLupKYrhe6"
      },
      "source": [
        "To enter the bakeoff, you simply need to use your original system to:\n",
        "\n",
        "1. Add a column named 'prediction' to `cs224u-sentiment-test-unlabeled.csv` with your model predictions (which are strings in {`positive`, `negative`, `neutral`}). The existing columns should remain.\n",
        "\n",
        "2. Save the file as `cs224u-sentiment-bakeoff-entry.csv`. Here is a good snippet of code for writing this file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfbs8r2arhe6"
      },
      "outputs": [],
      "source": [
        "# This is a placeholder for adding the \"prediction\" column:\n",
        "# bakeoff_df['prediction'] = # Use your model to add predictions.\n",
        "\n",
        "# Write to disk\n",
        "bakeoff_df.to_csv(\"cs224u-sentiment-bakeoff-entry.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBWbu-RQrhe7"
      },
      "source": [
        "In particular, you need to be sure that `example_id` is a column rather than an index when read in by Pandas. Here is a quick test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1ohuvYhrhe7"
      },
      "outputs": [],
      "source": [
        "def test_bakeoff_entry(filename=\"cs224u-sentiment-bakeoff-entry.csv\"):\n",
        "    gold_df = pd.read_csv(\n",
        "        os.path.join(\"data\", \"sentiment\", \"cs224u-sentiment-test-unlabeled.csv\"))\n",
        "    entry_df = pd.read_csv(filename)\n",
        "\n",
        "    # Check that no required columns are missing:\n",
        "    expected_cols = {'example_id', 'sentence', 'prediction'}\n",
        "    missing_cols = expected_cols - set(entry_df.columns)\n",
        "    errcount = 0\n",
        "    if len(missing_cols) != 0:\n",
        "        errcount += 1\n",
        "        print(f\"Entry is missing required columns {missing_cols}\")\n",
        "        return\n",
        "\n",
        "    # Check that the predictions are in our space:\n",
        "    labels = {'positive', 'negative', 'neutral'}\n",
        "    predtypes = set(entry_df.prediction.unique())\n",
        "    unexpected = predtypes - labels\n",
        "    if len(unexpected) != 0:\n",
        "        errcount += 1\n",
        "        print(f\"Prediction column has unexpected values: {unexpected}\")\n",
        "\n",
        "    # Check that the dataset hasn't been rearranged:\n",
        "    for colname in ('example_id', 'sentence'):\n",
        "        if not entry_df[colname].equals(gold_df[colname]):\n",
        "            errcount += 1\n",
        "            print(f\"Entry is misaligned with test data on column {colname}\")\n",
        "\n",
        "    # Clean bill of health:\n",
        "    if errcount == 0:\n",
        "        print(\"No errors detected with `test_bakeoff_entry`.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UP8NcWkrrhe7"
      },
      "outputs": [],
      "source": [
        "test_bakeoff_entry(\"cs224u-sentiment-bakeoff-entry.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0BryQqXrhe7"
      },
      "source": [
        "Submit the following files to Gradescope:\n",
        "\n",
        "* `hw_sentiment.ipynb` (this notebook)\n",
        "* `cs224u-sentiment-bakeoff-entry.csv` (bake-off output)\n",
        "\n",
        "Please make sure you use these filenames. The autograder looks for files with these names.\n",
        "\n",
        "You are not permitted to do any tuning of your system based on what you see in our bakeoff prediction file ‚Äì you should not study that file in anyway, beyond perhaps checking that it contains what you expected it to contain. The upload function will do some additional checking to ensure that your file is well-formed.\n",
        "\n",
        "People who enter will receive the additional homework point, and people whose systems achieve the top score will receive an additional 0.5 points. We will test the top-performing systems ourselves, and only systems for which we can reproduce the reported results will win the extra 0.5 points.\n",
        "\n",
        "Late entries will be accepted, but they cannot earn the extra 0.5 points."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7057d7bf33d74ed4b17beea4a59ef0e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e55b5182ddb40a99d76fdbc8f7d706e",
              "IPY_MODEL_0df4d264a8fd4d1c9c2a7d758c6f6cd4",
              "IPY_MODEL_b86c0a101c1048ff9d20b551f459643d"
            ],
            "layout": "IPY_MODEL_a7f79187a8d74ed280920c56aa4a2c26"
          }
        },
        "7e55b5182ddb40a99d76fdbc8f7d706e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_404e8edecc3e4ae9b48e9e647d25bd29",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_96dd7bf00d5b49578885ff2f8a8ff45f",
            "value": "100%"
          }
        },
        "0df4d264a8fd4d1c9c2a7d758c6f6cd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be23ca8c5b54424fa0735fcdd687619e",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5429e1f2bc14a209200a9f66337b06e",
            "value": 3
          }
        },
        "b86c0a101c1048ff9d20b551f459643d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b42ed1ae59364c22a0d70adff97cdc10",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ba3c5f0f91c445d089b8023fc2b4cd1f",
            "value": " 3/3 [00:00&lt;00:00,  4.33it/s]"
          }
        },
        "a7f79187a8d74ed280920c56aa4a2c26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "404e8edecc3e4ae9b48e9e647d25bd29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96dd7bf00d5b49578885ff2f8a8ff45f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be23ca8c5b54424fa0735fcdd687619e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5429e1f2bc14a209200a9f66337b06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b42ed1ae59364c22a0d70adff97cdc10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba3c5f0f91c445d089b8023fc2b4cd1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f66b59a0ccf24a3299bba1cc727b7e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55e8efbca3d54af6a92361a190cb89fe",
              "IPY_MODEL_4481997146954fb2b6ee9b8963617ef6",
              "IPY_MODEL_c1d43a8ddff449e0a315389b0674f218"
            ],
            "layout": "IPY_MODEL_15bb2f3e44a04b3f9a896faaadf5f3b2"
          }
        },
        "55e8efbca3d54af6a92361a190cb89fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7d51c21bc0642109783e056b4753987",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f4819479b0a64d79a0bf014967c21c03",
            "value": "100%"
          }
        },
        "4481997146954fb2b6ee9b8963617ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7261a38a3e24d3db23a1c76903b58cb",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b9634a5d8ce47ef8921ca57c42313e6",
            "value": 3
          }
        },
        "c1d43a8ddff449e0a315389b0674f218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9f0c4da0a6b42b09ed2718b3256c269",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_123e313617f84d53acbbafb50ae6d59f",
            "value": " 3/3 [00:00&lt;00:00, 30.89it/s]"
          }
        },
        "15bb2f3e44a04b3f9a896faaadf5f3b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7d51c21bc0642109783e056b4753987": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4819479b0a64d79a0bf014967c21c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7261a38a3e24d3db23a1c76903b58cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b9634a5d8ce47ef8921ca57c42313e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9f0c4da0a6b42b09ed2718b3256c269": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "123e313617f84d53acbbafb50ae6d59f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "590a9510737945c6beda1ce1d13f7baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_112c6de994e74ed0a4eeafe66fe65fdf",
              "IPY_MODEL_bd5cb3e93b4b45908dd9d526d8b77ced",
              "IPY_MODEL_3553377c78e540759134b292e5ec5b14"
            ],
            "layout": "IPY_MODEL_5abef5baebbb4e8e8a1b4e427e3e6873"
          }
        },
        "112c6de994e74ed0a4eeafe66fe65fdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ef05d3796044e49adaab3299749cfa6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_01d91b198f654c988846e213abdcc360",
            "value": "100%"
          }
        },
        "bd5cb3e93b4b45908dd9d526d8b77ced": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06d4e47fcd6a46a68e5ee75d341fb898",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1cc80309f70b48078f9b1bebc977076b",
            "value": 3
          }
        },
        "3553377c78e540759134b292e5ec5b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c073cae37bb545f38fffcbb3e810fa78",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e487f831c66e4306aa70891435b8c132",
            "value": " 3/3 [00:00&lt;00:00, 58.19it/s]"
          }
        },
        "5abef5baebbb4e8e8a1b4e427e3e6873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ef05d3796044e49adaab3299749cfa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01d91b198f654c988846e213abdcc360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06d4e47fcd6a46a68e5ee75d341fb898": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cc80309f70b48078f9b1bebc977076b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c073cae37bb545f38fffcbb3e810fa78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e487f831c66e4306aa70891435b8c132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1f5b070fb6544a9b4c4980a5bd6e6f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9220defbb3544051b74f0d07854dc8d7",
              "IPY_MODEL_cd582805b131443ab8a6a2842430645f",
              "IPY_MODEL_535adcd46c7f4b14bc2ddbacc088c724"
            ],
            "layout": "IPY_MODEL_60e3ff4bd2aa4a3184c777a23288ba4a"
          }
        },
        "9220defbb3544051b74f0d07854dc8d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a5548839c6c45729f52930d18e68e56",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0288a9cdcbb74083b0dcebf8e288b72e",
            "value": "config.json: 100%"
          }
        },
        "cd582805b131443ab8a6a2842430645f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e076bd12edf47e29a085fcbfe52a835",
            "max": 286,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c3448313a8942f998a7a54ba70b0de8",
            "value": 286
          }
        },
        "535adcd46c7f4b14bc2ddbacc088c724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2154c56dd8247d884cc451f6b727d8a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_68017290120e4b258e1e5ef72804cbba",
            "value": " 286/286 [00:00&lt;00:00, 10.1kB/s]"
          }
        },
        "60e3ff4bd2aa4a3184c777a23288ba4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a5548839c6c45729f52930d18e68e56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0288a9cdcbb74083b0dcebf8e288b72e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e076bd12edf47e29a085fcbfe52a835": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c3448313a8942f998a7a54ba70b0de8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2154c56dd8247d884cc451f6b727d8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68017290120e4b258e1e5ef72804cbba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10fe45885b6d4ea5b50362daa4d0f91f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30fc6416b018456a98e32c840e944867",
              "IPY_MODEL_e76c07a5b928463787291ba3139417c6",
              "IPY_MODEL_a199011b492e4b88b509325596aa4632"
            ],
            "layout": "IPY_MODEL_f5cb83bf8fa24ac4bc7d2323f1fc8504"
          }
        },
        "30fc6416b018456a98e32c840e944867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1ed63cb836d4d20a8c7cf4ffab66a00",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_717a48fc3a1846a78bafef4da36bb1d3",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "e76c07a5b928463787291ba3139417c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c440c490e990454e8bc6df3941a5a77a",
            "max": 45106985,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e3b84b4a9574aa8b3ad68e356972394",
            "value": 45106985
          }
        },
        "a199011b492e4b88b509325596aa4632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d1c8b9e4671478ca0025ce9e3570f87",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a4272638faf14f76b14e1f72068436d9",
            "value": " 45.1M/45.1M [00:03&lt;00:00, 15.0MB/s]"
          }
        },
        "f5cb83bf8fa24ac4bc7d2323f1fc8504": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1ed63cb836d4d20a8c7cf4ffab66a00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "717a48fc3a1846a78bafef4da36bb1d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c440c490e990454e8bc6df3941a5a77a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e3b84b4a9574aa8b3ad68e356972394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d1c8b9e4671478ca0025ce9e3570f87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4272638faf14f76b14e1f72068436d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3a7504fb7344764889b71117a80c93d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5242328f94eb435d9a023d1cdc4800f8",
              "IPY_MODEL_ebf8bceb2d59487587b552ea383f8aef",
              "IPY_MODEL_f2934afa462c42d9b0b954e6a7f7dc10"
            ],
            "layout": "IPY_MODEL_5c850eb5df8746b185e94e022f02fe0a"
          }
        },
        "5242328f94eb435d9a023d1cdc4800f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19767ba3fd12467da326ca80104d0c37",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_92b86fd37fd74dba95358cda1f7d0e83",
            "value": "vocab.txt: 100%"
          }
        },
        "ebf8bceb2d59487587b552ea383f8aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d98c57f75034ac3bb8d5f99b886d49e",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e4073838b2b4c8ab1534da052dd57be",
            "value": 231508
          }
        },
        "f2934afa462c42d9b0b954e6a7f7dc10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3204d22746d24370ab18b9f5f62b47bf",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cd79d4c3e1d0400f8508fbc6dca73222",
            "value": " 232k/232k [00:00&lt;00:00, 596kB/s]"
          }
        },
        "5c850eb5df8746b185e94e022f02fe0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19767ba3fd12467da326ca80104d0c37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92b86fd37fd74dba95358cda1f7d0e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d98c57f75034ac3bb8d5f99b886d49e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e4073838b2b4c8ab1534da052dd57be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3204d22746d24370ab18b9f5f62b47bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd79d4c3e1d0400f8508fbc6dca73222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}